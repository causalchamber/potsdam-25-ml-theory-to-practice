{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d193b13-0218-4440-aac5-8c7c710c88c4",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Project 3: Classifier two-sample tests\n",
    "\n",
    "```\n",
    "From ML Theory to Practice\n",
    "Universität Potsdam, fall semester 2025\n",
    "\n",
    "Authors: Juan L. Gamella and Simon Bing\n",
    "License: CC-BY-4.0 https://creativecommons.org/licenses/by/4.0/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9076d0-7be9-447f-86ad-b9812a31fa5b",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "These packages should already be installed in your Python virtual environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9170b71-d0a8-4a5a-ac13-076ff23d4b09",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e07970-9968-4f85-acca-1f47c1b9a89f",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Set the torch random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94d805-34d8-4acf-a28b-594727e4e485",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad9fe4-5797-4d7f-9f8e-4a5ce784affe",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Download the image dataset\n",
    "\n",
    "For this part we will use an existing dataset composed of images collected from the light tunnel.\n",
    "\n",
    "First, choose the directory where it should be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0be782-1916-4e55-8648-c4879d8c6127",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DOWNLOAD_DIR = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572a92f-51fc-4535-88c6-e6e2d53b8c6a",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "and download it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96768467-6f16-4ab7-aca0-f1229edb62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalchamber.datasets import Dataset\n",
    "\n",
    "# Download the dataset and store it, e.g., in the current directory\n",
    "dataset = Dataset('lt_color_regression_v1', root=DOWNLOAD_DIR, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9abad-a2b7-4aa0-a4b1-6d3274593f4c",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's visualize some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fa789-5b07-49ad-96fd-f8a2c915ec77",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_random_images(sample, n=5, seed=42):\n",
    "    plt.figure(figsize=(n*2, 2))\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for i,j in enumerate(rng.integers(len(sample), size=n)):\n",
    "        plt.subplot(1,n,i+1)\n",
    "        plt.imshow(sample[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2314008-104d-4cdd-9f5e-1c8020b20f4d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the observations and images from an experiment (see experiment names below)\n",
    "# Choose\n",
    "images_ref = dataset.get_experiment(name='reference').as_image_array(size='100')\n",
    "images_pol_45 = dataset.get_experiment(name='pol_1_45').as_image_array(size='100')\n",
    "plot_random_images(images_ref)\n",
    "plot_random_images(images_pol_45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea597f8-3bb7-4cba-a099-5ceec9db4ba7",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As you can see, it is quite hard to tell the difference at plain sight. If you look closer, you can notice the difference int the shape of the blur on the top of the image.\n",
    "\n",
    "That's quite a subtle difference. Let's try to build a two-sample test that can pick up on it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8805cd-b9e3-4535-9417-ba05ab8b9f86",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Preparing the data for training\n",
    "\n",
    "Before training, we need to do some preprocessing on our data so the training will be effective. In particular, we need to:\n",
    "\n",
    "- Scale the images so the pixel intensities are in `[-1,1]` instead of `[0,255]`\n",
    "- [One-hot encode](https://en.wikipedia.org/wiki/One-hot#Machine_learning_and_statistics) our class labels (i.e., sample A or B)\n",
    "- Transposes the images from `[height, width, color]` to `[color, height, width]`\n",
    "- Load the images and labels as a Tensor so they can be used by Pytorch.\n",
    "\n",
    "Pytorch uses the class `torch.utils.data.Dataset` to load data, and it is good practice to place all our preprocessing logic there.\n",
    "\n",
    "**⇨ Task**\n",
    "\n",
    "Complete the code below to write a class `TwoSampleDataset` that inherits from `torch.utils.data.Dataset` and carries out the pre-processing steps.\n",
    "\n",
    "For the one-hot encoding, you can use\n",
    "\n",
    "```python\n",
    "pd.get_dummies(<class_labels>).values.astype(float)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d232f-7e83-48fe-b853-e072d2239d9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TwoSampleDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, images_0, images_1):\n",
    "        \"\"\"Take two image arrays, preprocess them and store the images and labels indicating to which array each image belongs.\n",
    "\n",
    "        Pre-processing steps:\n",
    "          - Scale the images so the pixel intensities are in `[-1,1]` instead of `[0,255]`\n",
    "          - One-hot encode our class labels (i.e., sample A or B)\n",
    "        \"\"\"\n",
    "            \n",
    "        # TODO: your code goes here        \n",
    "\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns data from the dataset as a tuple of (images, labels).\n",
    "\n",
    "        Both must be tensors.\n",
    "        \"\"\"\n",
    "        \n",
    "        images = self.images[idx]\n",
    "        labels = self.labels[idx]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        images = torch.from_numpy(image).float()\n",
    "        labels = torch.from_numpy(labels).float()\n",
    "        \n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a81b60d-e12e-40d2-995f-633356a1f1aa",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Now, because we don't want to use all our images at once, write a simple function to sample random images from an image array. You can use the numpy random generator [`numpy.random.default_rng`](https://numpy.org/doc/stable/reference/random/generator.html) and its function [`choice`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html). Make sure you can set the seed for repeatability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ffc216-932e-448d-afd3-b76e92c7137f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_array(n, image_array, seed=42):\n",
    "    \"\"\"\n",
    "    Sample n images without replacement from the given image array, where images are ordered along the 0th axis.    \n",
    "    \"\"\"\n",
    "    # TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb474a8-ba78-49dc-baaa-53f4f1ece843",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Test everything works. Take two random samples of size `n=100` of images from the experiments `reference` and `pol_1_45` above, and load them into the `TwoSampleDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628f5aa-d6e0-4ac0-a835-076b7be7b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# TODO: Your code here\n",
    "# dataset = TwoSampleDataset(...)\n",
    "\n",
    "# Check if everything works, e.g., call dataset[0]\n",
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b3f81-1b37-4109-bd36-6522edc6dacf",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Building your classifier\n",
    "\n",
    "The next step is to define the architecture of your neural classifier.\n",
    "\n",
    "Let's with a simple [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron), consisting of\n",
    "\n",
    "- an input layer with `30000` neurons, i.e., the size of a flattened image\n",
    "- some hidden layers\n",
    "- output layer of size 2, i.e., the logits indicating the classification made by the model\n",
    "\n",
    "Use the ReLU activation function, e.g., `torch.nn.ReLU()`.\n",
    "\n",
    "**⇨ Task**\n",
    "\n",
    "Complete the code below to create a model like above. If you need to, you can use [this tutorial](https://docs.pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) for reference.\n",
    "\n",
    "Use a parameter `hidden_layers` to parametrize the number and size of hidden layers of the model, e.g., `hidden_layers = [10]` should result in a model with one hidden layers of 10 neurons, while `hidden_layers = [10,10,10]` should result in a model with three such layers stacked one after another. This will make your life easier later as we explore the effects of model capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed914c-ee5f-4c12-a15e-f50b448ebaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, hidden_layers = [], device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Construct layers\n",
    "        # First layer is just a flattening operation\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Build the input, hidden and output layers\n",
    "        # TODO: your code here\n",
    "\n",
    "        # Store the model in the correct device (by default `cpu`)\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward pass of the model\n",
    "        # x is the input\n",
    "        # should return the values of the two neurons in the last layer (logits)\n",
    "        # TODO: your code goes here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac296636-87f0-4d8c-8259-dd577d349c76",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Training the classifier\n",
    "\n",
    "Now we need to write the training loop that will fit the classifier to our images.\n",
    "\n",
    "There are some things we need to do.\n",
    "\n",
    "**⇨ Task**\n",
    "\n",
    "First, write a function `split_dataset(dataset, ratios)` which takes in a dataset and splits it at random into smaller disjoint datasets following the given ratios. You can follow the example for `random_split` shown [here](https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.random_split). Make sure you set a random seed for repeatability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e873ee5-cb0c-4c57-a880-ee6e83f32a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46e3b2-2b1d-4c2a-bcff-da6e8e2dba37",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The training loop\n",
    "\n",
    "Now it's time to write the training loop for our model. It needs several ingredients\n",
    "\n",
    "#### The model\n",
    "\n",
    "e.g., an instance of your `SimpleMLP` class. For now, let's start with one hidden layer with 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c8f89-5b19-48b4-884e-4c953686fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMLP(hidden_layers = [10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50151722-1e96-4759-a608-d9ed10104170",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### The loss function\n",
    "\n",
    "We will use the [cross-entropy loss](https://en.wikipedia.org/wiki/Cross-entropy) (a.k.a. the KL divergence) to compare the ground-truth and the class distribution produced by your model. Fortunately, it is already nicely implemented in [`torch.nn.CrossEntropyLoss()`](https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) to directly manage logits (the output of our model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc028f-c062-4d46-8541-ba7f4acaab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff79b6-8d3b-439e-af53-1e0c13118147",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### The optimizer\n",
    "\n",
    "We will use the ADAM optimizer. Set a learning rate of `1e-3` and a weight decay of `1e-5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1367531e-7f72-4bc1-a312-55464cee8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "opt_args = {'lr': 1e-3, 'weight_decay': 1e-5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8e32c-1955-44e0-abb4-42bbebf0864b",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### The data\n",
    "\n",
    "We will need a training dataset and a separate test dataset to monitor the training. We can also set aside a validation dataset to use only once the model has been trained.\n",
    "\n",
    "**⇨ Task**\n",
    "\n",
    "As before, take two random samples of size `n=500` of images from the experiments `reference` and `pol_1_45` above, load them into a `TwoSampleDataset` and split them into training, test and validation datasets with `ratios=[10, 90, 900]`, i.e., we want only 10 images for training and a large validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fbc007-0712-421e-9e2a-347eda5d7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2eeba-bdd2-4c02-951b-26c6f957d3d8",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Now write the training loop for your model. You can follow the steps in [this tutorial](https://docs.pytorch.org/tutorials/beginner/basics/optimization_tutorial.html) and adjust it to your code.\n",
    "\n",
    "As you train, remember to store the training and test loss after each batch in `train_losses` and `test_losses` for later plotting and diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f994c25a-2b85-43ef-bafa-003b2ddfcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a3abbd-9126-4273-90ca-1c625fa03c9c",
   "metadata": {},
   "source": [
    "### Training and diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd289a0e-d407-4c80-8651-b93afbf21e02",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Now, train your model for 100 epochs with a batch size of 10, and plot the training and test losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98bd6ab-d27c-4d21-8338-3e893a431052",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SimpleMLP(hidden_layers = [10])\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam\n",
    "opt_args = {'lr': 1e-3, 'weight_decay': 1e-5}\n",
    "\n",
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a76ba6-9608-4b65-9b48-bd2953295ffd",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Looking at your train/test loss curves, would you say your model has trained correctly? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f66b0e-2f29-4fdc-bc59-fb95ccc89553",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbf3c7c3-8982-44cb-b30e-5145949123e9",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "  \n",
    "Now, train and evaluate two more models:\n",
    "\n",
    "- A flat model (`hidden_layers = []`), i.e., a linear transformation of the inputs.\n",
    "- A more complex model, with three hidden layers of 64 neurons, i.e., `hidden_layers = [64, 64, 64]`\n",
    "\n",
    "As before, plot the curves of the training and test loss for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffff041-6ad0-4da0-8c37-234084bd9427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885eedc9-8d3d-4cc0-aba1-387de0e61e5f",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Now, train each of the three models 10 times, and plot the resulting loss curves.\n",
    "\n",
    "The curves should look different for each training run - make sure you're setting the random seed correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d64a34-b32f-4af9-8a95-3a8b22b0acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0853d8-dee4-44c2-aace-c2391446be93",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Do you observe any difference in the training of each model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3a36b4-d617-4dd5-b79b-09e35c3dd8a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "661d2985-47ef-4449-9192-3e3d8831096d",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Are any models overfitting to the training data? Which model do you think generalizes best? Explain your reasoning / intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e01a0-4a6f-4e1b-a9b2-04e3956abca7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "744bf05e-a85b-487f-a00d-7db13b4ed371",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Transforming our classifier into a Two-Sample Test\n",
    "\n",
    "Now comes the fun part, as we transform our classifier into a two-sample test.\n",
    "\n",
    "Given a test-set $\\mathcal{D}_{te} = \\{(z_1, l_1), \\ldots (z_{n_{te}}, l_{n_{te}})\\}$, recall that the test statistic (eq. (2) in the paper) is given by\n",
    "\n",
    "$$\\hat{t} := \\frac{1}{n_{te}} \\sum_{(z_i, l_i) \\in \\mathcal{D}_{te}} \\mathbb{I}\\left [ \\mathbb{I} \\left( f(z_i) > \\frac{1}{2}\\right) = l_i\\right],$$\n",
    "\n",
    "where $f$ is a classifier and $\\mathbb{I}$ is the [indicator function](https://en.wikipedia.org/wiki/Indicator_function).\n",
    "\n",
    "Let's build all these ingredients.\n",
    "\n",
    "#### The softmax function\n",
    "\n",
    "Above, $f$ is a function $f: \\mathcal{X} \\to [0,1]$ that denotes the estimated probability that $X \\in \\mathcal{X}$ belongs to class 0. However, our model returns two real numbers (logits) as its prediction.\n",
    "\n",
    "To transform them into probabilities, we can use the [softmax function](https://en.wikipedia.org/wiki/Softmax_function): given logits $\\boldsymbol{z} = (z_1, \\ldots, z_K) \\in \\mathbb{R}^K$, it returns a vector $\\sigma(\\boldsymbol{z}) \\in [0,1]^K$ where each component is given by\n",
    "\n",
    "$$\\sigma(\\boldsymbol{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}.$$\n",
    "\n",
    "**⇨ Task**\n",
    "\n",
    "Implement the softmax function and perform the simple checks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469d9f8-fb27-4a35-beb9-8b9e6f8002d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # TODO: your code goes here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f1d33-3d80-48c9-bd08-2f60c5a7220e",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Some basic checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7408e-84e7-4c61-8e52-c76c436c4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (softmax([1,1]) == [0.5,0.5]).all() # Softmax of n same elements is [1/n, ..., 1/n]\n",
    "assert (softmax([0,-np.inf]) == [1,0]).all() # Softmax of [0, -infinity] = [1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f7dc6-55c4-449e-9ec9-b2d440269084",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Now, write a function to compute the accuracy of a model on a given dataset. To transform a tensor `t` (e.g., the output of the model) to a numpy array, you can use\n",
    "\n",
    "```python\n",
    "t.cpu().detach().numpy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5683e543-c6eb-4847-9d6e-dcde5db86573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(mode, dataset):\n",
    "    # TODO: your code goes here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed1000-d31a-402a-b568-47728d2b008a",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now we will evaluate the accuracy of the three models (base model, flat model and complex model) on the left-out validation dataset..\n",
    "\n",
    "[❓] **Question** Which model do you think will achieve higher accuracy? Make a guess and explain your intuition or reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ec1c1-96d8-42b3-84f8-1388ad390a82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fed16b8-f68a-463f-bc4a-4f4e79ea797a",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Now, evaluate the accuracy of three models you trained above on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3c28f-ca0f-4bb0-87d9-51b69d6b507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d00123-5dea-4dc7-9582-6d7a2fb93d50",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Was your guess correct? If not, what do you think is going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa0f9ee-5c06-40b1-bdd8-38c77f426940",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486f4968-c99a-4f09-8b3d-592175f25093",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Computing a p-value\n",
    "\n",
    "Now we will write the code to compute a p-value given the accuracy produced by the model.\n",
    "\n",
    "[❓] **Question** Given the accuracy of the three models, what do you expect their p-values to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bfdab8-b1f6-4d63-9406-5fb408319470",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63128635-b402-467f-a52f-bdec81643bee",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Under the null hypothesis and small $n_{te}$ what distribution does the number of correct labels $n_{te}\\hat{t}$ follow? Hint: see section 3.1 of the [paper](https://arxiv.org/pdf/1610.06545)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54101f43-7371-4497-ab42-3bba7f161fd6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f6c12cf-8ef5-4f22-82b7-5783f2b35cb4",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Write a function to compute the cumulative distribution function $F$ of this distribution. You can check its Wikipedia page for the formula.\n",
    "\n",
    "> Hint: you can just write a wrapper around the `.cdf` function provided by [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html#discrete-distributions) for the correct distribution (see [here](https://docs.scipy.org/doc/scipy/reference/stats.html#discrete-distributions))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa889d7-ebac-4dac-9da2-4d8f847d0057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf(t, n):\n",
    "    # TODO: your code goes here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342af859-c74a-4d6b-8a05-fba5c52c0443",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "You can check your work with these simple tests (NOTE: failure means you made a mistake, no failed tests doesn't mean you didn't)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62623e-f57a-4623-ac0f-c3f0bafcef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cdf(0, 1) == 0.5\n",
    "assert cdf(1, 1) == 1\n",
    "assert cdf(0, 2) == 0.25\n",
    "assert cdf(1, 2) == 0.75\n",
    "assert cdf(2, 2) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7130a-d127-40b3-80b3-62fb70ee97a5",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Remember that the p-value is the probability, under the null hypothesis, of observing a number of correctly classified observations more extreme than the one obtained. That is, given an accuracy $\\hat{t}$ in a test set of size $n_{te}$, the probability is\n",
    "\n",
    "$$P(X \\geq k \\cup X \\leq n_{te}-k) \\text{ if } \\hat{t} > \\frac{1}{2}, \\text{ and } P(X \\leq k \\cup X \\geq n_{te}-k) \\text{ otherwise},$$\n",
    "\n",
    "where $k := \\hat{t}n_{te}$.\n",
    "\n",
    "\n",
    "\n",
    "[❓] **Question** Rewrite the above expression in terms of the cumulative distribution function (CDF) $F$ that you computed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b3391-2d1c-46c8-bea9-e8ea763c2a07",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f96f52eb-8a8a-4882-bfb5-43cb3bfc122c",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Based on your derivation, write a function that takes in the accuracy of the model on a dataset, the size of the dataset, and returns the p-value under the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818b47c-bb52-4be3-a82c-34a9fee6fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pvalue(accuracy, n):\n",
    "    # TODO: Your code goes here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61e91e8-d1d2-40cd-9ec5-c075ebc00c18",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Again, here are some checks for your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b12c443-ab41-4a25-acc6-ba90ce9dad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert compute_pvalue(0.5, 100) == 1\n",
    "assert compute_pvalue(0.5, 10) == 1\n",
    "assert compute_pvalue(0.5, 2) == 1\n",
    "assert compute_pvalue(1, 100) == compute_pvalue(0, 100)\n",
    "assert np.isclose(compute_pvalue(0, 100), 0)\n",
    "assert np.isclose(compute_pvalue(1, 100), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9eafa6-d6c4-4513-a1e1-e526724bbcb3",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Now, compute the the p-values for the three models on the validation dataset that left out above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ebe6b8-7689-4e6f-a07a-6c0965bc58fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in zip(['base', 'flat', 'complex'], [trained_model, flat_model, complex_model]):\n",
    "    accuracy = compute_accuracy(model, dataset_validate)\n",
    "    pval = compute_pvalue(accuracy, len(dataset_validate))\n",
    "    print(name)    \n",
    "    print('  accuracy', accuracy)\n",
    "    print('  pvalue', pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeb677a-51f9-4103-b935-52df8be3bfbd",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Did the p-values match your guess above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668b4ce-0866-490c-8c7e-6a72377a5f80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64479c05-74ae-4ca2-b220-51c47fefd6b6",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Putting it all together\n",
    "\n",
    "Now let's put it all together into a single function that implements our classifier two-sample test.\n",
    "\n",
    "\n",
    "The function takes in the two samples we want to test and\n",
    "\n",
    "1. Combines them into a Pytorch dataset\n",
    "2. Splits the dataset into train and test\n",
    "3. Trains a classifier\n",
    "4. Computes the accuracy of the classifier on the test set\n",
    "5. Returns the accuracy statistic and the corresponding p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0549b1-23a0-4b55-acdf-35d314d51063",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Complete the code below. Make sure that you can ensure repeatability with the `seed` parameter.\n",
    "\n",
    "For diagnosing, also return the trained model and the loss curves observed during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd592a-de28-42e0-acb6-1c18d0549c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c2st(sample_a, sample_b, model, ratios, seed=42):\n",
    "    # Combine sample_a and sample_b into TwoSampleDataset\n",
    "    # TODO: your code goes here\n",
    "    \n",
    "    # Split into train / test datasets (use ratios and seed)    \n",
    "    # TODO: your code goes here\n",
    "\n",
    "    # Train your model\n",
    "    # TODO: your code here\n",
    "\n",
    "    # Compute the accuracy and p-value on the test set\n",
    "    # TODO: your code here\n",
    "    \n",
    "    # Return the p-value, accuracy statistic and the trained model\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b309b-6088-4ce8-9853-f47df3232a22",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Run the code below to check that everything is working as you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ecde8-5593-4ece-bf88-82a711e60f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_a = sample_array(50, images_ref)\n",
    "sample_b = sample_array(50, images_pol_45)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = SimpleMLP(hidden_layers = [10])\n",
    "\n",
    "pval,accuracy,_,train_losses,test_losses = c2st(sample_a, sample_b, model, [10,90], seed=42)\n",
    "\n",
    "print(f\"p-value = {pval} (accuracy = {accuracy:.3f})\")\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Train loss\")\n",
    "plt.plot(test_losses, label=\"Test loss\")\n",
    "plt.title('Flat model')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d0ad0-798d-4e55-a0b4-6842259474b2",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Evaluating the level of the test\n",
    "\n",
    "Let's evaluate the level of our test and how it is affected by model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f23782-826d-4a79-b16f-57b3f642e7e5",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Let's begin by evaluating the level of our test.\n",
    "\n",
    "Split the `reference` dataset into 200 samples with `n=50` observations each.\n",
    "\n",
    "Then, write a function that takes in a model and runs the 2CST on 100 pairs of these samples, storing the accuracy, pvalues and training / test loss curves. Use `10` observations for the training data and `90` for the testing data.\n",
    "\n",
    "> Hint: remember to instantiate a new model for each of the 100 repetitions, or you will be training the same model over and over again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7342e3e-07ef-4d23-8ee2-d83923e548eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321fc91-fbc1-427d-a30d-a3012730e3c5",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** What do you expect the distributions of accuracies and p-values to look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae699f70-6ed8-43b1-9694-11092ccfba58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d59ddfa7-40cb-4590-bdf2-b6468a203c71",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Using [`sns.histplot`](https://seaborn.pydata.org/generated/seaborn.histplot.html), plot the distributions of the accuracies and pvalues for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011daa05-a69a-4527-9127-550c82002d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f745a1c-b136-4606-82d6-71dbbc4505fc",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Did the results match your expectations? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a091b757-e2a3-43a6-af36-b6e50bca48d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c927d23a-a246-41bd-8946-eb56fbe2e584",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Will all tests have correct level? Make a guess and explain your intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab06891-492d-426e-ba24-8761f9c3fe32",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4d3115d-94ba-417d-bda4-bbe3274fed70",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Using the stored p-values, make a plot with the nominal level $\\alpha$ on the x-axis, and the actual rejection rate on the y-axis. Combine the results for all models into a single plot. For reference, plot the $y=x$ line in the range `[0,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385659d-fdab-4b4b-9613-322873a83178",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1, 100)\n",
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d2be2-d7a7-409b-8bf1-56d920e5db0b",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Do the tests appear valid at all levels $\\alpha$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05565560-4cf2-4f71-aee5-9239f5514002",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0359317c-7fa0-49fe-87f0-14916472c243",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Do the tests appear well *calibrated* at all levels $\\alpha$? Make a guess and explain your intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008df90-4e95-4ead-9ccb-92b1c4147105",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f771367c-4f0e-4f3f-94cc-39053c5fb5ad",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Does the model complexity affect the *validity* of the test? Why or why not? Explain your reasoning and/or intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d0fe1b-c5ff-4ec5-b542-00ef36bb2787",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa5e49dc-9d3a-4cd8-86ab-e77e2d83debf",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Does the model complexity affect the calibration of the test? Why or why not? Explain your reasoning and/or intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6d8c3d-e89a-497f-aa82-734aa4497db2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ad1cb18-784c-4edc-a4e1-a689a04f357f",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** What if a model does not train correctly? Is the test still valid at level $\\alpha$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b840511-4363-4451-ac4b-58cd6312f78e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3e4dd7b-1e65-4ea3-b47d-989fbdd3514a",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Will any classifier $f: \\mathcal{X} \\to [0,1]$ also result in a valid test?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece885f-b036-4006-8f59-a10af9e71504",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50ef69c4-4a13-45b8-ab44-03a7864417fa",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Evaluating the power of the test\n",
    "\n",
    "Now we will evaluate the power of our test and how it is affected by model complexity.\n",
    "\n",
    "As in the previous project, we will evaluate power by see how each test rejects the null hypothesis when it is not true (i.e., images from different experiments).\n",
    "\n",
    "[❓] **Question** Which test do you expect to be more powerful? Explain your reasoning / intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f2ee7e-dccd-4b2a-aa87-f5113af37497",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8491357-057a-488c-8719-6a1949ebbff7",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Adapt the code used for our level experiments above. This time, take 100 samples of size `n=50` from the `reference` experiment, and 100 samples from the `pol_1_45` experiment. You can use the function `sample_array` that you wrote before.\n",
    "\n",
    "Then, write a function that takes in a model and runs the 2CST on the 100 pairs of these samples, storing the accuracy and pvalues and training/test curves. Use `10` observations for the training data and `90` for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6041189-2643-46d8-b778-87e81b3d6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8cbddf-be26-4e43-9c53-84edf84ddd0c",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "As before, plot the distributions of the accuracies and p-values for each model using [`sns.histplot`](https://seaborn.pydata.org/generated/seaborn.histplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000efc5-acce-42d1-887d-7878f807e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edebc94-d571-47cb-8180-c96b8aebf78b",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** From the above plots, which test is the most powerful? Which is the least? Explain your reasoning / intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9ed4d-9acd-4319-bdc2-a24162f25a2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f4b66e0-1a27-43c6-8876-b1c47b9b7118",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** From the above plots, can you already tell which test is the most powerful? Which is the least? Explain your reasoning / intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925717e3-0d0c-4437-8eaf-0a779462a9a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8456f42-38f1-4980-8020-425f6a740780",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Now, using the stored p-values, calculate how often each test rejects the null hypothesis for different levels $\\alpha$.\n",
    "\n",
    "Plot your results in a plot with $\\alpha$ on the x-axis and the actual rejection rate on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a84b044-e7b2-4418-aeb4-066696a15bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1, 1000)\n",
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bcea49-7d1f-4328-a1be-dd4018384c18",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Which test is more powerful? Did your prediction hold?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0f69c-26b7-4394-9341-adb47e21a617",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b367b13a-ac65-4965-b200-a8f91c6df731",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Now, repeat the above experiment & analysis, but this time increase the training sample size to 100.\n",
    "\n",
    "As before, plot the distributions of p-values and the rejection rate of each test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf93bc2d-d1c5-46fc-a40c-dcc44a42bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175fa8a5-2216-4fd6-8fb0-0308ff348bbb",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Which test is now the most powerful? If there has been a change, can you provide intuition as to why this happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbffe04-e10b-42c0-a6ae-a337710dd171",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90e4b4d1-d8bc-4d72-9996-3e51558848a6",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**⇨ Task**\n",
    "\n",
    "Plot the training / test loss curves resulting from the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc11fa8-a7b4-4cd3-bf2d-dc9f2f699d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21f69b-07f9-471c-963c-5a5ebae329e9",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[❓] **Question** Do the loss curves support your hypothesis? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ca914-c1de-45f6-957e-d137027e8e6d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
